{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d7aa179",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_PATH = \"../data/processed/Analytics_Processed_df.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e35f469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score , precision_score\n",
    "from keras.layers import Dense,Dropout, BatchNormalization\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00f0cf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BWinnerW</th>\n",
       "      <th>Income</th>\n",
       "      <th>Need/Money</th>\n",
       "      <th>FamlyMembs</th>\n",
       "      <th>TR/Guest</th>\n",
       "      <th>TR/Camp</th>\n",
       "      <th>TR/Own</th>\n",
       "      <th>TR/Rental</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>4</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1701 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BWinnerW  Income  Need/Money  FamlyMembs  TR/Guest  TR/Camp  TR/Own  \\\n",
       "1            0     146           0           8         0        0       1   \n",
       "2            0      40           1           4         0        0       1   \n",
       "3            1      40           1           9         1        0       0   \n",
       "4            2      40           1          10         0        0       0   \n",
       "5            1      94           1           5         1        0       0   \n",
       "...        ...     ...         ...         ...       ...      ...     ...   \n",
       "1697         0      40           1           6         0        0       0   \n",
       "1698         0      40           1           6         0        0       1   \n",
       "1699         4     206           1          10         0        0       0   \n",
       "1700         3      40           1           5         0        1       0   \n",
       "1701         4      69           1           5         1        0       0   \n",
       "\n",
       "      TR/Rental Cluster  \n",
       "1             0       0  \n",
       "2             0       1  \n",
       "3             0       1  \n",
       "4             1       1  \n",
       "5             0       1  \n",
       "...         ...     ...  \n",
       "1697          1       1  \n",
       "1698          0       1  \n",
       "1699          1       0  \n",
       "1700          0       1  \n",
       "1701          0       1  \n",
       "\n",
       "[1701 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data \n",
    "df = pd.read_pickle(EXPORT_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df2719e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 256)               2304      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 8)                 1032      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,241\n",
      "Trainable params: 36,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "#model.add(Dense(8116, input_dim=3, activation='relu')) #input layer with 64 neurons\n",
    "model.add(tf.keras.layers.Dense(256, input_shape=(x.shape[1],), activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(2048,activation= 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(8,activation= 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) #output layer with 1 neuron \n",
    "model.compile(loss=['binary_crossentropy'], optimizer= tf.keras.optimizers.Nadam(4e-6),metrics = [tf.keras.metrics.AUC(curve='ROC')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4ba5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "180d6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(x , y, test_size = 0.20 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3087a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = tf.expand_dims(x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab3063b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 3s 4ms/step - loss: 0.9551 - auc_2: 0.5281 - val_loss: 0.7401 - val_auc_2: 0.8435\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8460 - auc_2: 0.5108 - val_loss: 0.6910 - val_auc_2: 0.6945\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7778 - auc_2: 0.5210 - val_loss: 0.6506 - val_auc_2: 0.7541\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7222 - auc_2: 0.5338 - val_loss: 0.6269 - val_auc_2: 0.8500\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7172 - auc_2: 0.5169 - val_loss: 0.6131 - val_auc_2: 0.9154\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6804 - auc_2: 0.5504 - val_loss: 0.6028 - val_auc_2: 0.9728\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6714 - auc_2: 0.5665 - val_loss: 0.5940 - val_auc_2: 0.9848\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6706 - auc_2: 0.5569 - val_loss: 0.5866 - val_auc_2: 0.9942\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6642 - auc_2: 0.5687 - val_loss: 0.5786 - val_auc_2: 0.9967\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6853 - auc_2: 0.5271 - val_loss: 0.5714 - val_auc_2: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cbb4a9c370>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split = 0.20,batch_size = 3,epochs = 10)#,callbacks=[callbacks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "087046ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step\n",
      "[[0.61774033]\n",
      " [0.6402562 ]\n",
      " [0.644988  ]\n",
      " [0.6828782 ]\n",
      " [0.6133629 ]\n",
      " [0.6258813 ]\n",
      " [0.61384654]\n",
      " [0.7292541 ]\n",
      " [0.7255302 ]\n",
      " [0.6152237 ]\n",
      " [0.61386967]\n",
      " [0.62813723]\n",
      " [0.72724277]\n",
      " [0.72680175]\n",
      " [0.7304264 ]\n",
      " [0.723498  ]\n",
      " [0.6138106 ]\n",
      " [0.6168562 ]\n",
      " [0.72963077]\n",
      " [0.64722157]\n",
      " [0.72741824]\n",
      " [0.72734135]\n",
      " [0.63147044]\n",
      " [0.7260215 ]\n",
      " [0.6897228 ]\n",
      " [0.61115164]\n",
      " [0.7293849 ]\n",
      " [0.7304264 ]\n",
      " [0.6259424 ]\n",
      " [0.61831367]\n",
      " [0.61597604]\n",
      " [0.6321246 ]\n",
      " [0.7300432 ]\n",
      " [0.7248053 ]\n",
      " [0.7304264 ]\n",
      " [0.7297388 ]\n",
      " [0.6290538 ]\n",
      " [0.7297388 ]\n",
      " [0.6159549 ]\n",
      " [0.72635806]\n",
      " [0.6101222 ]\n",
      " [0.6170546 ]\n",
      " [0.7248233 ]\n",
      " [0.62264526]\n",
      " [0.6126878 ]\n",
      " [0.63352585]\n",
      " [0.72964567]\n",
      " [0.6303069 ]\n",
      " [0.62579995]\n",
      " [0.72711635]\n",
      " [0.7243657 ]\n",
      " [0.6354465 ]\n",
      " [0.7253261 ]\n",
      " [0.67012846]\n",
      " [0.7292501 ]\n",
      " [0.727508  ]\n",
      " [0.61479294]\n",
      " [0.6267984 ]\n",
      " [0.62320244]\n",
      " [0.7299666 ]\n",
      " [0.7240262 ]\n",
      " [0.6260847 ]\n",
      " [0.6328209 ]\n",
      " [0.69322747]\n",
      " [0.61293185]\n",
      " [0.7248233 ]\n",
      " [0.73053324]\n",
      " [0.65556693]\n",
      " [0.72608143]\n",
      " [0.7281526 ]\n",
      " [0.6337931 ]\n",
      " [0.7250771 ]\n",
      " [0.62607616]\n",
      " [0.7294856 ]\n",
      " [0.72890717]\n",
      " [0.725709  ]\n",
      " [0.6685645 ]\n",
      " [0.6144753 ]\n",
      " [0.6175386 ]\n",
      " [0.7289784 ]\n",
      " [0.61607003]\n",
      " [0.6589497 ]\n",
      " [0.72983557]\n",
      " [0.72724277]\n",
      " [0.6238451 ]\n",
      " [0.6802847 ]\n",
      " [0.64865935]\n",
      " [0.6167728 ]\n",
      " [0.6288424 ]\n",
      " [0.674801  ]\n",
      " [0.6185824 ]\n",
      " [0.7299666 ]\n",
      " [0.7260215 ]\n",
      " [0.7238792 ]\n",
      " [0.61149347]\n",
      " [0.72599643]\n",
      " [0.7271634 ]\n",
      " [0.6830196 ]\n",
      " [0.6284583 ]\n",
      " [0.72963274]\n",
      " [0.72680175]\n",
      " [0.6191786 ]\n",
      " [0.61397004]\n",
      " [0.6111774 ]\n",
      " [0.6309321 ]\n",
      " [0.7271634 ]\n",
      " [0.7289784 ]\n",
      " [0.6130959 ]\n",
      " [0.72701055]\n",
      " [0.613525  ]\n",
      " [0.7251483 ]\n",
      " [0.6092129 ]\n",
      " [0.7299666 ]\n",
      " [0.61403674]\n",
      " [0.613537  ]\n",
      " [0.6159624 ]\n",
      " [0.6950634 ]\n",
      " [0.7281363 ]\n",
      " [0.6318029 ]\n",
      " [0.6663293 ]\n",
      " [0.6146973 ]\n",
      " [0.63729334]\n",
      " [0.61505806]\n",
      " [0.7256048 ]\n",
      " [0.6904097 ]\n",
      " [0.72680175]\n",
      " [0.61824507]\n",
      " [0.72618484]\n",
      " [0.6222799 ]\n",
      " [0.6498737 ]\n",
      " [0.7250771 ]\n",
      " [0.69517785]\n",
      " [0.6151934 ]\n",
      " [0.6128614 ]\n",
      " [0.7304264 ]\n",
      " [0.65436256]\n",
      " [0.72608143]\n",
      " [0.6177846 ]\n",
      " [0.72818387]\n",
      " [0.610941  ]\n",
      " [0.7266794 ]\n",
      " [0.6182549 ]\n",
      " [0.63516927]\n",
      " [0.7268454 ]\n",
      " [0.6124715 ]\n",
      " [0.7294741 ]\n",
      " [0.7281363 ]\n",
      " [0.72964036]\n",
      " [0.6152629 ]\n",
      " [0.62059397]\n",
      " [0.72619027]\n",
      " [0.609029  ]\n",
      " [0.727508  ]\n",
      " [0.7301375 ]\n",
      " [0.6236394 ]\n",
      " [0.6119571 ]\n",
      " [0.724747  ]\n",
      " [0.6643234 ]\n",
      " [0.62894213]\n",
      " [0.6303555 ]\n",
      " [0.636803  ]\n",
      " [0.67626584]\n",
      " [0.61800116]\n",
      " [0.62641066]\n",
      " [0.67606324]\n",
      " [0.62098384]\n",
      " [0.7297388 ]\n",
      " [0.6245879 ]\n",
      " [0.64816976]\n",
      " [0.61227405]\n",
      " [0.6478086 ]\n",
      " [0.613041  ]\n",
      " [0.72919476]\n",
      " [0.7248053 ]\n",
      " [0.7255308 ]\n",
      " [0.72788405]\n",
      " [0.6151813 ]\n",
      " [0.7299666 ]\n",
      " [0.63351405]\n",
      " [0.66013664]\n",
      " [0.725709  ]\n",
      " [0.63596374]\n",
      " [0.6175187 ]\n",
      " [0.61723727]\n",
      " [0.72570735]\n",
      " [0.6897053 ]\n",
      " [0.614348  ]\n",
      " [0.6361165 ]\n",
      " [0.72682565]\n",
      " [0.62758934]\n",
      " [0.6331274 ]\n",
      " [0.61370265]\n",
      " [0.61008203]\n",
      " [0.7255308 ]\n",
      " [0.6368344 ]\n",
      " [0.6587525 ]\n",
      " [0.6242037 ]\n",
      " [0.61333114]\n",
      " [0.67369735]\n",
      " [0.7277422 ]\n",
      " [0.614859  ]\n",
      " [0.68389136]\n",
      " [0.6144948 ]\n",
      " [0.7277063 ]\n",
      " [0.72471696]\n",
      " [0.7299666 ]\n",
      " [0.6467937 ]\n",
      " [0.72680175]\n",
      " [0.7294856 ]\n",
      " [0.63756275]\n",
      " [0.72948563]\n",
      " [0.72516584]\n",
      " [0.725355  ]\n",
      " [0.72724277]\n",
      " [0.6143752 ]\n",
      " [0.70195156]\n",
      " [0.7297388 ]\n",
      " [0.612097  ]\n",
      " [0.6138643 ]\n",
      " [0.62749773]\n",
      " [0.7304264 ]\n",
      " [0.64474136]\n",
      " [0.62726176]\n",
      " [0.7247459 ]\n",
      " [0.62748516]\n",
      " [0.62213904]\n",
      " [0.7292892 ]\n",
      " [0.72964567]\n",
      " [0.6171674 ]\n",
      " [0.7249154 ]\n",
      " [0.7300514 ]\n",
      " [0.6152823 ]\n",
      " [0.72496486]\n",
      " [0.72528267]\n",
      " [0.6477386 ]\n",
      " [0.7241979 ]\n",
      " [0.6300958 ]\n",
      " [0.61271113]\n",
      " [0.6404192 ]\n",
      " [0.64405686]\n",
      " [0.6621432 ]\n",
      " [0.6759022 ]\n",
      " [0.72680175]\n",
      " [0.6303071 ]\n",
      " [0.6131649 ]\n",
      " [0.61124593]\n",
      " [0.7284545 ]\n",
      " [0.62033445]\n",
      " [0.7292501 ]\n",
      " [0.6241232 ]\n",
      " [0.6528957 ]\n",
      " [0.68101627]\n",
      " [0.6760932 ]\n",
      " [0.72682565]\n",
      " [0.61905605]\n",
      " [0.61540836]\n",
      " [0.6161872 ]\n",
      " [0.72578007]\n",
      " [0.72618484]\n",
      " [0.6244788 ]\n",
      " [0.6172034 ]\n",
      " [0.6134295 ]\n",
      " [0.7272979 ]\n",
      " [0.6351663 ]\n",
      " [0.6638149 ]\n",
      " [0.61110103]\n",
      " [0.6209333 ]\n",
      " [0.72724277]\n",
      " [0.7276628 ]\n",
      " [0.614639  ]\n",
      " [0.6133194 ]\n",
      " [0.6136522 ]\n",
      " [0.6339288 ]\n",
      " [0.63430744]\n",
      " [0.7249154 ]\n",
      " [0.6175366 ]\n",
      " [0.72983557]\n",
      " [0.6102828 ]\n",
      " [0.72608143]\n",
      " [0.7295361 ]\n",
      " [0.6095008 ]\n",
      " [0.6133613 ]\n",
      " [0.6160666 ]\n",
      " [0.67039734]\n",
      " [0.6317257 ]\n",
      " [0.61619365]\n",
      " [0.7271634 ]\n",
      " [0.72983557]\n",
      " [0.7266794 ]\n",
      " [0.6685147 ]\n",
      " [0.63403916]\n",
      " [0.7280924 ]\n",
      " [0.61464226]\n",
      " [0.6895801 ]\n",
      " [0.72892916]\n",
      " [0.6334624 ]\n",
      " [0.6697779 ]\n",
      " [0.61153275]\n",
      " [0.6491013 ]\n",
      " [0.66879547]\n",
      " [0.6187508 ]\n",
      " [0.72919476]\n",
      " [0.69181824]\n",
      " [0.6161744 ]\n",
      " [0.63133544]\n",
      " [0.7256048 ]\n",
      " [0.62853914]\n",
      " [0.7295361 ]\n",
      " [0.61596894]\n",
      " [0.6239983 ]\n",
      " [0.6521952 ]\n",
      " [0.6179767 ]\n",
      " [0.7256048 ]\n",
      " [0.6640918 ]\n",
      " [0.72892094]\n",
      " [0.6339212 ]\n",
      " [0.7297388 ]\n",
      " [0.72618484]\n",
      " [0.72651476]\n",
      " [0.72440004]\n",
      " [0.72608143]\n",
      " [0.72471696]\n",
      " [0.6669164 ]\n",
      " [0.67666894]\n",
      " [0.6187243 ]\n",
      " [0.62607616]\n",
      " [0.63381165]\n",
      " [0.63693845]\n",
      " [0.6391838 ]\n",
      " [0.61279845]\n",
      " [0.6376975 ]\n",
      " [0.62206364]\n",
      " [0.61053544]\n",
      " [0.72962904]\n",
      " [0.67214245]\n",
      " [0.6300043 ]\n",
      " [0.6128317 ]\n",
      " [0.64060825]\n",
      " [0.62237406]\n",
      " [0.6129702 ]\n",
      " [0.72952986]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a983b5d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1701, 341]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1701, 341]"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58dfe2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step\n",
      "[[0.61774033]\n",
      " [0.6402562 ]\n",
      " [0.644988  ]\n",
      " [0.6828782 ]\n",
      " [0.6133629 ]\n",
      " [0.6258813 ]\n",
      " [0.61384654]\n",
      " [0.7292541 ]\n",
      " [0.7255302 ]\n",
      " [0.6152237 ]\n",
      " [0.61386967]\n",
      " [0.62813723]\n",
      " [0.72724277]\n",
      " [0.72680175]\n",
      " [0.7304264 ]\n",
      " [0.723498  ]\n",
      " [0.6138106 ]\n",
      " [0.6168562 ]\n",
      " [0.72963077]\n",
      " [0.64722157]\n",
      " [0.72741824]\n",
      " [0.72734135]\n",
      " [0.63147044]\n",
      " [0.7260215 ]\n",
      " [0.6897228 ]\n",
      " [0.61115164]\n",
      " [0.7293849 ]\n",
      " [0.7304264 ]\n",
      " [0.6259424 ]\n",
      " [0.61831367]\n",
      " [0.61597604]\n",
      " [0.6321246 ]\n",
      " [0.7300432 ]\n",
      " [0.7248053 ]\n",
      " [0.7304264 ]\n",
      " [0.7297388 ]\n",
      " [0.6290538 ]\n",
      " [0.7297388 ]\n",
      " [0.6159549 ]\n",
      " [0.72635806]\n",
      " [0.6101222 ]\n",
      " [0.6170546 ]\n",
      " [0.7248233 ]\n",
      " [0.62264526]\n",
      " [0.6126878 ]\n",
      " [0.63352585]\n",
      " [0.72964567]\n",
      " [0.6303069 ]\n",
      " [0.62579995]\n",
      " [0.72711635]\n",
      " [0.7243657 ]\n",
      " [0.6354465 ]\n",
      " [0.7253261 ]\n",
      " [0.67012846]\n",
      " [0.7292501 ]\n",
      " [0.727508  ]\n",
      " [0.61479294]\n",
      " [0.6267984 ]\n",
      " [0.62320244]\n",
      " [0.7299666 ]\n",
      " [0.7240262 ]\n",
      " [0.6260847 ]\n",
      " [0.6328209 ]\n",
      " [0.69322747]\n",
      " [0.61293185]\n",
      " [0.7248233 ]\n",
      " [0.73053324]\n",
      " [0.65556693]\n",
      " [0.72608143]\n",
      " [0.7281526 ]\n",
      " [0.6337931 ]\n",
      " [0.7250771 ]\n",
      " [0.62607616]\n",
      " [0.7294856 ]\n",
      " [0.72890717]\n",
      " [0.725709  ]\n",
      " [0.6685645 ]\n",
      " [0.6144753 ]\n",
      " [0.6175386 ]\n",
      " [0.7289784 ]\n",
      " [0.61607003]\n",
      " [0.6589497 ]\n",
      " [0.72983557]\n",
      " [0.72724277]\n",
      " [0.6238451 ]\n",
      " [0.6802847 ]\n",
      " [0.64865935]\n",
      " [0.6167728 ]\n",
      " [0.6288424 ]\n",
      " [0.674801  ]\n",
      " [0.6185824 ]\n",
      " [0.7299666 ]\n",
      " [0.7260215 ]\n",
      " [0.7238792 ]\n",
      " [0.61149347]\n",
      " [0.72599643]\n",
      " [0.7271634 ]\n",
      " [0.6830196 ]\n",
      " [0.6284583 ]\n",
      " [0.72963274]\n",
      " [0.72680175]\n",
      " [0.6191786 ]\n",
      " [0.61397004]\n",
      " [0.6111774 ]\n",
      " [0.6309321 ]\n",
      " [0.7271634 ]\n",
      " [0.7289784 ]\n",
      " [0.6130959 ]\n",
      " [0.72701055]\n",
      " [0.613525  ]\n",
      " [0.7251483 ]\n",
      " [0.6092129 ]\n",
      " [0.7299666 ]\n",
      " [0.61403674]\n",
      " [0.613537  ]\n",
      " [0.6159624 ]\n",
      " [0.6950634 ]\n",
      " [0.7281363 ]\n",
      " [0.6318029 ]\n",
      " [0.6663293 ]\n",
      " [0.6146973 ]\n",
      " [0.63729334]\n",
      " [0.61505806]\n",
      " [0.7256048 ]\n",
      " [0.6904097 ]\n",
      " [0.72680175]\n",
      " [0.61824507]\n",
      " [0.72618484]\n",
      " [0.6222799 ]\n",
      " [0.6498737 ]\n",
      " [0.7250771 ]\n",
      " [0.69517785]\n",
      " [0.6151934 ]\n",
      " [0.6128614 ]\n",
      " [0.7304264 ]\n",
      " [0.65436256]\n",
      " [0.72608143]\n",
      " [0.6177846 ]\n",
      " [0.72818387]\n",
      " [0.610941  ]\n",
      " [0.7266794 ]\n",
      " [0.6182549 ]\n",
      " [0.63516927]\n",
      " [0.7268454 ]\n",
      " [0.6124715 ]\n",
      " [0.7294741 ]\n",
      " [0.7281363 ]\n",
      " [0.72964036]\n",
      " [0.6152629 ]\n",
      " [0.62059397]\n",
      " [0.72619027]\n",
      " [0.609029  ]\n",
      " [0.727508  ]\n",
      " [0.7301375 ]\n",
      " [0.6236394 ]\n",
      " [0.6119571 ]\n",
      " [0.724747  ]\n",
      " [0.6643234 ]\n",
      " [0.62894213]\n",
      " [0.6303555 ]\n",
      " [0.636803  ]\n",
      " [0.67626584]\n",
      " [0.61800116]\n",
      " [0.62641066]\n",
      " [0.67606324]\n",
      " [0.62098384]\n",
      " [0.7297388 ]\n",
      " [0.6245879 ]\n",
      " [0.64816976]\n",
      " [0.61227405]\n",
      " [0.6478086 ]\n",
      " [0.613041  ]\n",
      " [0.72919476]\n",
      " [0.7248053 ]\n",
      " [0.7255308 ]\n",
      " [0.72788405]\n",
      " [0.6151813 ]\n",
      " [0.7299666 ]\n",
      " [0.63351405]\n",
      " [0.66013664]\n",
      " [0.725709  ]\n",
      " [0.63596374]\n",
      " [0.6175187 ]\n",
      " [0.61723727]\n",
      " [0.72570735]\n",
      " [0.6897053 ]\n",
      " [0.614348  ]\n",
      " [0.6361165 ]\n",
      " [0.72682565]\n",
      " [0.62758934]\n",
      " [0.6331274 ]\n",
      " [0.61370265]\n",
      " [0.61008203]\n",
      " [0.7255308 ]\n",
      " [0.6368344 ]\n",
      " [0.6587525 ]\n",
      " [0.6242037 ]\n",
      " [0.61333114]\n",
      " [0.67369735]\n",
      " [0.7277422 ]\n",
      " [0.614859  ]\n",
      " [0.68389136]\n",
      " [0.6144948 ]\n",
      " [0.7277063 ]\n",
      " [0.72471696]\n",
      " [0.7299666 ]\n",
      " [0.6467937 ]\n",
      " [0.72680175]\n",
      " [0.7294856 ]\n",
      " [0.63756275]\n",
      " [0.72948563]\n",
      " [0.72516584]\n",
      " [0.725355  ]\n",
      " [0.72724277]\n",
      " [0.6143752 ]\n",
      " [0.70195156]\n",
      " [0.7297388 ]\n",
      " [0.612097  ]\n",
      " [0.6138643 ]\n",
      " [0.62749773]\n",
      " [0.7304264 ]\n",
      " [0.64474136]\n",
      " [0.62726176]\n",
      " [0.7247459 ]\n",
      " [0.62748516]\n",
      " [0.62213904]\n",
      " [0.7292892 ]\n",
      " [0.72964567]\n",
      " [0.6171674 ]\n",
      " [0.7249154 ]\n",
      " [0.7300514 ]\n",
      " [0.6152823 ]\n",
      " [0.72496486]\n",
      " [0.72528267]\n",
      " [0.6477386 ]\n",
      " [0.7241979 ]\n",
      " [0.6300958 ]\n",
      " [0.61271113]\n",
      " [0.6404192 ]\n",
      " [0.64405686]\n",
      " [0.6621432 ]\n",
      " [0.6759022 ]\n",
      " [0.72680175]\n",
      " [0.6303071 ]\n",
      " [0.6131649 ]\n",
      " [0.61124593]\n",
      " [0.7284545 ]\n",
      " [0.62033445]\n",
      " [0.7292501 ]\n",
      " [0.6241232 ]\n",
      " [0.6528957 ]\n",
      " [0.68101627]\n",
      " [0.6760932 ]\n",
      " [0.72682565]\n",
      " [0.61905605]\n",
      " [0.61540836]\n",
      " [0.6161872 ]\n",
      " [0.72578007]\n",
      " [0.72618484]\n",
      " [0.6244788 ]\n",
      " [0.6172034 ]\n",
      " [0.6134295 ]\n",
      " [0.7272979 ]\n",
      " [0.6351663 ]\n",
      " [0.6638149 ]\n",
      " [0.61110103]\n",
      " [0.6209333 ]\n",
      " [0.72724277]\n",
      " [0.7276628 ]\n",
      " [0.614639  ]\n",
      " [0.6133194 ]\n",
      " [0.6136522 ]\n",
      " [0.6339288 ]\n",
      " [0.63430744]\n",
      " [0.7249154 ]\n",
      " [0.6175366 ]\n",
      " [0.72983557]\n",
      " [0.6102828 ]\n",
      " [0.72608143]\n",
      " [0.7295361 ]\n",
      " [0.6095008 ]\n",
      " [0.6133613 ]\n",
      " [0.6160666 ]\n",
      " [0.67039734]\n",
      " [0.6317257 ]\n",
      " [0.61619365]\n",
      " [0.7271634 ]\n",
      " [0.72983557]\n",
      " [0.7266794 ]\n",
      " [0.6685147 ]\n",
      " [0.63403916]\n",
      " [0.7280924 ]\n",
      " [0.61464226]\n",
      " [0.6895801 ]\n",
      " [0.72892916]\n",
      " [0.6334624 ]\n",
      " [0.6697779 ]\n",
      " [0.61153275]\n",
      " [0.6491013 ]\n",
      " [0.66879547]\n",
      " [0.6187508 ]\n",
      " [0.72919476]\n",
      " [0.69181824]\n",
      " [0.6161744 ]\n",
      " [0.63133544]\n",
      " [0.7256048 ]\n",
      " [0.62853914]\n",
      " [0.7295361 ]\n",
      " [0.61596894]\n",
      " [0.6239983 ]\n",
      " [0.6521952 ]\n",
      " [0.6179767 ]\n",
      " [0.7256048 ]\n",
      " [0.6640918 ]\n",
      " [0.72892094]\n",
      " [0.6339212 ]\n",
      " [0.7297388 ]\n",
      " [0.72618484]\n",
      " [0.72651476]\n",
      " [0.72440004]\n",
      " [0.72608143]\n",
      " [0.72471696]\n",
      " [0.6669164 ]\n",
      " [0.67666894]\n",
      " [0.6187243 ]\n",
      " [0.62607616]\n",
      " [0.63381165]\n",
      " [0.63693845]\n",
      " [0.6391838 ]\n",
      " [0.61279845]\n",
      " [0.6376975 ]\n",
      " [0.62206364]\n",
      " [0.61053544]\n",
      " [0.72962904]\n",
      " [0.67214245]\n",
      " [0.6300043 ]\n",
      " [0.6128317 ]\n",
      " [0.64060825]\n",
      " [0.62237406]\n",
      " [0.6129702 ]\n",
      " [0.72952986]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_test)\n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a911bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume y_true and y_scores are the true labels and predicted scores for your dataset\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, y_pred_train)\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f1efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
